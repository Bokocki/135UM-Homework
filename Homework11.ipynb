{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9906be45",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Bokocki/135UM-Homework/blob/main/Homework11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4Ar3Nf6gOX4Y",
   "metadata": {
    "id": "4Ar3Nf6gOX4Y"
   },
   "source": [
    "# **Homework Assignment: Understanding Deconvolution in Autoencoders**\n",
    "---------------\n",
    "\n",
    "In class, we worked with autoencoders built from multilayer perceptrons (MLPs). However, encoders are often constructed using convolutional architectures to better capture spatial patterns. In this assignment, you'll explore how the decoder can use deconvolutional (transposed convolution) layers to reverse and mirror the operations performed by the convolutional encoder.\n",
    "\n",
    "While convolutional encoders are relatively well understood, **decoding (or upsampling) the compressed representation** using **deconvolutional layers** (also known as **transposed convolutions**) often raises questions.\n",
    "\n",
    "This assignment is particularly relevant because deconvolution is a core component of the U-Net architecture, a prominent neural network used extensively in image segmentation tasks.\n",
    "\n",
    "Your main objective is to deeply understand **how transposed convolution layers work**, and explain them in both words and visuals.\n",
    "\n",
    "\n",
    "## **The Objective**\n",
    "\n",
    "Understand and clearly explain how **transposed convolutions** work. Use 2D transposed convolutions and a small grid of 2D points as a working example.\n",
    "\n",
    "You may need to do some additional reading to complete this assignment.\n",
    "\n",
    "## **Tasks & Deliverables**\n",
    "\n",
    "### 1. **Theory Exploration**\n",
    "\n",
    "Using markdown cells in your Colab notebook, answer the following:\n",
    "\n",
    "- What is a **transposed convolution**?\n",
    "- How does it differ from a regular convolution?\n",
    "- How does it upsample feature maps?\n",
    "- What are **stride**, **padding**, and **kernel size**, and how do they influence the result in a transposed convolution?\n",
    "- To earn full two points, your explanation must be detailed enough for a reader to reproduce the upsampling process step by step.\n",
    "\n",
    "\n",
    "### 2. **Manual Diagram (by your hand, not a generated image)**\n",
    "\n",
    "Carefully plan and draw **by hand** a diagram or a set of diagrams that:\n",
    "\n",
    "- Explain the process of using **transposed convolution**.\n",
    "- Use an example of a **small input grid of 2D points** which gets expanded into a larger output grid.\n",
    "- Explain how stride, padding, and the kernel shape affect the result.\n",
    "- Show intermediate steps of the operation, not just input and output.\n",
    "\n",
    "**Scan or photograph your diagram(s)**, and upload it to your **GitHub repository** for this course.\n",
    "\n",
    "Then embed it in your Colab notebook using markdown (you can find examples on *how to do it* in previous notebooks related to this class, e.g. the one on linear regression or the one on the MLP network).\n",
    "\n",
    "\n",
    "### 3. **Publish on GitHub**  \n",
    "   - Place the Colab notebook in your **GitHub repository** for this course.\n",
    "   - In your repository’s **README**, add a **link** to the notebook and also include an **“Open in Colab”** badge at the top of the notebook so it can be launched directly from GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fd7ce-ab13-41f2-b037-9dbb1fc816e2",
   "metadata": {},
   "source": [
    "# Solution to the Homework\n",
    "---\n",
    "## Theoretical explanations\n",
    "\n",
    "In a typical convolutional network, the output feature map is downsampled, i.e. its spatial dimensions are smaller than those of the input. A convolution operation is defined by the following parameters:\n",
    "\n",
    "- **padding** $(p)$: the number of zeros added around the input,\n",
    "- **stride** $(s)$: the step size with which the kernel slides across the input,  \n",
    "- **kernel size** $(k)$: the dimensions of the filter.\n",
    "\n",
    "Given an input of size $i$, the output size $o$ after applying a standard convolution is computed as\n",
    "$$\n",
    "o = \\frac{i + 2p - k}{s} + 1.\n",
    "$$\n",
    "\n",
    "A transposed convolutional layer is typically used for upsampling, i.e. generating an output feature map with larger spatial dimensions than the input. Like regular convolution, it is defined by padding, stride, and kernel size. However, in this case, the padding and stride refer to a hypothetical convolution that, if applied to the output, would produce the given input size.\n",
    "\n",
    "Importantly, a transposed convolution is not the inverse of a convolution, i.e. it doesn’t recover the original input. Instead, it reconstructs the dimensions that would have been reduced by a standard convolution. It's a learnable way of growing feature maps.\n",
    "\n",
    "The operation can be broken down into the following steps:\n",
    "\n",
    "1. Compute new parameters:  \n",
    "   $z = s - 1$ (zero insertion spacing),  \n",
    "   $p' = k - p - 1$ (padding to be added).\n",
    "\n",
    "2. Insert $z$ zeros between input rows and columns.\n",
    "\n",
    "3. Pad the expanded input with $p'$ zeros around the borders.\n",
    "\n",
    "4. Apply a standard convolution with stride 1 on the resulting input.\n",
    "\n",
    "Given input size $i$, kernel size $k$, padding $p$, and stride $s$, the output size $o$ of a transposed convolution is given by:\n",
    "$$\n",
    "o = (i - 1)s + k - 2p.\n",
    "$$\n",
    "\n",
    "Below is a more detailed discussion of how stride, padding, and kernel size affect the output in a transposed convolution. This can already be seen from the algorithm described above and will be further illustrated by an example.\n",
    "\n",
    "- **Stride** ($s$):  \n",
    "In transposed convolution, stride controls how much the output is \"stretched.\" When the stride is greater than 1, zeros are inserted between input elements, expanding the input grid before the convolution is applied. This results in a larger output size. However, if the stride is too large, the output may become sparse, introducing too many zeros and making the reconstructed image appear unintelligible.\n",
    "\n",
    "- **Padding** ($p$):  \n",
    "Padding in transposed convolution affects how much of the output is trimmed around the borders. Increasing the padding reduces the output size.\n",
    "\n",
    "- **Kernel Size** ($k$):  \n",
    "The kernel size determines the area that each input element influences in the output. A larger kernel means each input value is spread over a wider area, increasing the size of the output feature map.\n",
    "\n",
    "## Example of transposed convolution\n",
    "\n",
    "Below is a hand-drawn example of a transposed convolution, illustrating the steps above using a small 2D input and kernel. The effect of stride, padding, and kernel size can be seen in the intermediate steps.\n",
    "\n",
    "![example](https://raw.githubusercontent.com/Bokocki/135UM-Homework/refs/heads/main/transposed_convolution_example.png)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
